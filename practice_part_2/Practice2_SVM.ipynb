{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c86cca7d-c00c-49a2-85cc-a34027748802",
   "metadata": {},
   "source": [
    "# Pratice 2: Quantum Support Vector Machines\n",
    "\n",
    "MQIST 2025/26: Quantum Computing and Machine Learning\n",
    "\n",
    "Alfredo Chavert Sancho\n",
    "\n",
    "Pedro Herrero Maldonado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16a3ecb-a8b3-4c7d-8f6d-cf794a249c1f",
   "metadata": {},
   "source": [
    "## Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1568b52d-febf-405f-88c7-56a268113f5d",
   "metadata": {},
   "source": [
    "The `load_breast_cancer` function from `sklearn.datasets` is used to load the breast cancer dataset. This dataset contains features computed from breast cancer biopsy images, along with labels indicating whether the cancer is malignant or benign. So this is a binary classification problem. There are 30 features in total and 569 samples which are divided into:\n",
    "\n",
    "- 357 benign samples labeled as 1\n",
    "- 212 malignant samples labeled as 0\n",
    "\n",
    "As measure to evaluate the performance of our quantum neural network, we will use **recall** of the positive class labeled with 0, which is the ratio of correctly predicted positive malignant cases to the total actual positive instances in the dataset (true positives and false negatives). \n",
    "$$\n",
    "\\text{Recall} = \\frac{\\text{True Malignant}}{\\text{True Malignant} + \\text{False Benign}}\n",
    "$$\n",
    "\n",
    "This is particularly important in medical diagnosis tasks, where minimizing false negatives (i.e., failing to identify actual positive cases) is crucial. Therefore, our goal in this work is to maximize this metric in our experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8db4cede-2b4c-4a89-83a2-972f1c2886eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (569, 30)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer()\n",
    "X = data.data # features\n",
    "y = data.target # labels\n",
    "\n",
    "print(\"Original shape:\", X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff4a8ec-8aaf-4e76-a714-ba70cb1cf1eb",
   "metadata": {},
   "source": [
    "For the prepocessing the data to be used in the quantum neural network, we will use  ``StandardScaler`` from ``sklearn.preprocessing`` to normalize it  since all the data is numeric.\n",
    "\n",
    "We will also use ``PCA`` from ``sklearn.decomposition`` to reduce the dimensionality of the data to reduce the number of qubits needed in the quantum neural network. This transformation helps in capturing the most significant variance in the data while reducing its complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc089e00-0f7d-4320-8ecc-f0e2c84d67b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after PCA: (569, 4)\n",
      "Explained variance: [0.44272026 0.18971182 0.09393163 0.06602135]\n",
      "Total variance explained: 0.7923850582446098\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Standardize (important for PCA)\n",
    "# scaler = StandardScaler()\n",
    "norm = StandardScaler() \n",
    "X_norm = norm.fit_transform(X)\n",
    "\n",
    "# Apply PCA to reduce to 4 dimensions\n",
    "pca = PCA(n_components = 4)\n",
    "X_pca = pca.fit_transform(X_norm)\n",
    "\n",
    "print(\"Shape after PCA:\", X_pca.shape) # (150, 2)\n",
    "print(\"Explained variance:\", pca.explained_variance_ratio_)\n",
    "print(\"Total variance explained:\", pca.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252c1776",
   "metadata": {},
   "source": [
    "The ``MinMaxScaler`` from ``sklearn.preprocessing`` is used to scale the data to a range between 0 and 1. This scaling is important because the quantum circuits used in the neural network often require input values to be within specific ranges for effective encoding into quantum states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f6a00cc-4bc5-4cd3-a593-76296e84e77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler() \n",
    "X_scaled = scaler.fit_transform(X_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57290b1c-c01a-4e5e-87aa-bee660a73700",
   "metadata": {},
   "source": [
    "Finally, we will split the dataset into training and testing sets using ``train_test_split`` from ``sklearn.model_selection``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40929e81-675f-4400-88b8-d8e32d40e817",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from qiskit_algorithms.utils import algorithm_globals\n",
    "\n",
    "# Set the seed so results are reproducible\n",
    "algorithm_globals.random_seed = 42\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=algorithm_globals.random_seed,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5b8742-70c0-4742-b24f-0df498407c31",
   "metadata": {},
   "source": [
    "## Classical SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79b6400",
   "metadata": {},
   "source": [
    "Classical SVM is implemented using ``SVC`` from ``sklearn.svm`` with a radial basis function (RBF) kernel. The model is trained on the training set and evaluated on the test set. The recall metric is calculated to assess the performance of the classical SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3fce11-92dc-4bf3-8361-ad584298b578",
   "metadata": {},
   "source": [
    "### Linear kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed88d9d",
   "metadata": {},
   "source": [
    "Fisrtly, we will implement a linear kernel SVM as a baseline model. The linear kernel is suitable for linearly separable data and serves as a reference point for comparing the performance of more complex kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adeab12e-9100-4281-b1e1-422311339767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.94        43\n",
      "           1       0.93      1.00      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.97      0.94      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "svc_linear = SVC(kernel = 'linear', gamma='auto')\n",
    "svc_linear.fit(X_train, y_train)\n",
    "\n",
    "y_svc_linear = svc_linear.predict(X_test)\n",
    "report_svc_linear = classification_report(y_test, y_svc_linear)\n",
    "print(report_svc_linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d068b288",
   "metadata": {},
   "source": [
    "The recall obtained with the linear kernel SVM is 0.88"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafbea3a-a9c6-4e55-93a2-0b5717ee55ad",
   "metadata": {},
   "source": [
    "### Polynomial kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8285c4bd",
   "metadata": {},
   "source": [
    "Next, we will implement a polynomial kernel SVM. The polynomial kernel allows for modeling non-linear decision boundaries by transforming the input space into a higher-dimensional space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3978ec81-70d9-4f95-8995-f863ec4bacc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        43\n",
      "           1       0.62      1.00      0.77        71\n",
      "\n",
      "    accuracy                           0.62       114\n",
      "   macro avg       0.31      0.50      0.38       114\n",
      "weighted avg       0.39      0.62      0.48       114\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fredi\\.conda\\envs\\qml\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\fredi\\.conda\\envs\\qml\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\fredi\\.conda\\envs\\qml\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "svc_poly = SVC(kernel = 'poly', gamma='auto') \n",
    "svc_poly.fit(X_train, y_train)\n",
    "\n",
    "y_svc_poly = svc_poly.predict(X_test)\n",
    "report_svc_poly = classification_report(y_test, y_svc_poly)\n",
    "print(report_svc_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327e1451",
   "metadata": {},
   "source": [
    "The recall obtained with the polynomial kernel SVM is 0.00 which is worse than the linear kernel. This suggests that the polynomial kernel may not be suitable for this particular dataset or that the chosen degree of the polynomial is not optimal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1db40f-60bc-4668-9f4d-9e41d2f31529",
   "metadata": {},
   "source": [
    "### RBF kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72b30bc",
   "metadata": {},
   "source": [
    "Finally, we will implement an RBF kernel SVM. The RBF kernel is a popular choice for non-linear classification tasks as it can handle complex decision boundaries by mapping the input data into an infinite-dimensional space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eee75acd-3bba-4564-857d-585d72efd351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.94        43\n",
      "           1       0.93      1.00      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.97      0.94      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc_rbf = SVC(kernel = 'rbf', gamma='auto')\n",
    "svc_rbf.fit(X_train, y_train)\n",
    "\n",
    "y_svc_rbf = svc_rbf.predict(X_test)\n",
    "report_svc_rbf = classification_report(y_test, y_svc_rbf)\n",
    "print(report_svc_rbf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf3b32e",
   "metadata": {},
   "source": [
    "The recall obtained with the polynomial kernel SVM is 0.88 which is the same as the linear kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8a15ab",
   "metadata": {},
   "source": [
    "The performance of the classical SVM with Linear, Polynomial, and RBF kernel is as follows:\n",
    "\n",
    "| Kernel     | Recall (0) |\n",
    "|------------|--------|\n",
    "| Linear     | 0.88  |\n",
    "| Polynomial | 0.00  |\n",
    "| RBF        | 0.88  |\n",
    "\n",
    "We can observe that both the  Linear and RBF kernels perform the best in terms of recall for positive cases marked as 0 for this dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e257c86c-8394-4798-9f23-9d67dbd3169a",
   "metadata": {},
   "source": [
    "## Quantum SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256fc433",
   "metadata": {},
   "source": [
    "In this section, we will implement a Quantum Support Vector Machine (QSVM) using the Qiskit library. QSVM leverages the principles of quantum computing to perform classification tasks, potentially offering advantages over classical SVMs, especially for complex datasets.\n",
    "\n",
    "Let's try different quantum kernels/feature maps and compare their performance in terms of recall for the positive class labeled with 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dab82c0-b5e5-4fa3-97cc-675f7d314d00",
   "metadata": {},
   "source": [
    "### Z Feature Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9c9743",
   "metadata": {},
   "source": [
    "Let's start by implementing a QSVM using the Z Feature Map. The Z Feature Map encodes classical data into quantum states using rotations around the Z-axis of the Bloch sphere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "063190ae-d349-4692-9850-d371d72a8559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95        43\n",
      "           1       0.96      0.99      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.97      0.96      0.96       114\n",
      "weighted avg       0.97      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from qiskit_machine_learning.kernels import FidelityQuantumKernel\n",
    "from qiskit_machine_learning.algorithms import QSVC\n",
    "from qiskit.circuit.library import ZFeatureMap\n",
    "\n",
    "num_features = X_pca.shape[1]\n",
    "\n",
    "kernel = FidelityQuantumKernel(feature_map = ZFeatureMap(feature_dimension = num_features, reps = 2))\n",
    "qsvc_z = QSVC(quantum_kernel = kernel)\n",
    "qsvc_z.fit(X_train, y_train)\n",
    "y_pred_qsvc_z = qsvc_z.predict(X_test)\n",
    "\n",
    "report_qsvc_z = classification_report(y_test, y_pred_qsvc_z)\n",
    "print(report_qsvc_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3464d9",
   "metadata": {},
   "source": [
    "We obtain a recall of 0.93 with this feature map, which is better than the classical SVM with linear and RBF kernels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6966d0-66e2-4f1f-8995-f741ce145bb0",
   "metadata": {},
   "source": [
    "### ZZ Feature Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426b6a39",
   "metadata": {},
   "source": [
    "The ZZ Feature Map extends the Z Feature Map by incorporating entangling gates between qubits, allowing for more complex data representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "893e9c4d-a578-4f07-93a2-962c741c8591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90        43\n",
      "           1       0.93      0.96      0.94        71\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.93      0.92      0.92       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from qiskit.circuit.library import ZZFeatureMap\n",
    "\n",
    "kernel = FidelityQuantumKernel(feature_map = ZZFeatureMap(feature_dimension = num_features, reps = 2))\n",
    "qsvc_zz = QSVC(quantum_kernel = kernel)\n",
    "qsvc_zz.fit(X_train, y_train)\n",
    "y_pred_qsvc_zz = qsvc_zz.predict(X_test)\n",
    "\n",
    "report_qsvc_zz = classification_report(y_test, y_pred_qsvc_zz)\n",
    "print(report_qsvc_zz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a4f2e9",
   "metadata": {},
   "source": [
    "We get a recall of 0.88 with this feature map, which is the same as the classical SVM with linear and RBF kernels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffc6349-798d-4c1e-a575-97cc9fd04e10",
   "metadata": {},
   "source": [
    "### Pauli Feature Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636f802e",
   "metadata": {},
   "source": [
    "Finally Pauli Feature Map uses a combination of Pauli gates to encode the data into quantum states, providing a richer representation of the input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13496fbe-97da-4266-8cd0-f0a81ee867e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.51      0.57        43\n",
      "           1       0.74      0.83      0.78        71\n",
      "\n",
      "    accuracy                           0.71       114\n",
      "   macro avg       0.69      0.67      0.68       114\n",
      "weighted avg       0.70      0.71      0.70       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from qiskit.circuit.library import PauliFeatureMap\n",
    "\n",
    "kernel = FidelityQuantumKernel(feature_map = PauliFeatureMap(feature_dimension = num_features, reps = 2, paulis = ['Z', 'XX', 'ZXZ']))\n",
    "qsvc_pauli = QSVC(quantum_kernel = kernel)\n",
    "qsvc_pauli.fit(X_train, y_train)\n",
    "y_pred_qsvc_pauli = qsvc_pauli.predict(X_test)\n",
    "\n",
    "report_qsvc_pauli = classification_report(y_test, y_pred_qsvc_pauli)\n",
    "print(report_qsvc_pauli)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f45835",
   "metadata": {},
   "source": [
    "In this case, we achieve a recall of 0.51, which is lower than the previous quantum feature maps and the classical SVM with linear and RBF kernels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53770064-7687-4ad5-8306-d723b0dec22e",
   "metadata": {},
   "source": [
    "### ZFeatureMap + C=0.1 + OVO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f493ccf-a76f-4a61-82d1-4df140562d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.70      0.82        43\n",
      "           1       0.85      1.00      0.92        71\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.92      0.85      0.87       114\n",
      "weighted avg       0.90      0.89      0.88       114\n",
      "\n",
      "Training time: 250 seconds\n"
     ]
    }
   ],
   "source": [
    "from qiskit_machine_learning.kernels import FidelityQuantumKernel\n",
    "from qiskit_machine_learning.algorithms import QSVC\n",
    "from qiskit.circuit.library import ZFeatureMap\n",
    "from sklearn.metrics import classification_report\n",
    "import time\n",
    "\n",
    "num_features = X_train.shape[1]\n",
    "\n",
    "kernel = FidelityQuantumKernel(feature_map = ZFeatureMap(feature_dimension = num_features, reps = 2))\n",
    "qsvc3 = QSVC(quantum_kernel = kernel, C = 0.1)\n",
    "start = time.time()\n",
    "qsvc3.fit(X_train, y_train)\n",
    "elapsed3 = time.time() - start\n",
    "y_pred_qsvc3 = qsvc3.predict(X_test)\n",
    "\n",
    "report_qsvc3 = classification_report(y_test, y_pred_qsvc3)\n",
    "print(report_qsvc3)\n",
    "print(f\"Training time: {round(elapsed3)} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe8c579-fdc4-40d9-bc81-347e4bee3062",
   "metadata": {},
   "source": [
    "### ZFeatureMap + C=10.0 + OVO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4f62787-7e84-459f-b5df-44bfcc61341b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96        43\n",
      "           1       0.97      0.99      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n",
      "Training time: 261 seconds\n"
     ]
    }
   ],
   "source": [
    "from qiskit_machine_learning.kernels import FidelityQuantumKernel\n",
    "from qiskit_machine_learning.algorithms import QSVC\n",
    "from qiskit.circuit.library import ZFeatureMap\n",
    "from sklearn.metrics import classification_report\n",
    "import time\n",
    "\n",
    "num_features = X_train.shape[1]\n",
    "\n",
    "kernel = FidelityQuantumKernel(feature_map = ZFeatureMap(feature_dimension = num_features, reps = 2))\n",
    "qsvc4 = QSVC(quantum_kernel = kernel, C = 10.0)\n",
    "start = time.time()\n",
    "qsvc4.fit(X_train, y_train)\n",
    "elapsed4 = time.time() - start\n",
    "y_pred_qsvc4 = qsvc4.predict(X_test)\n",
    "\n",
    "report_qsvc4 = classification_report(y_test, y_pred_qsvc4)\n",
    "print(report_qsvc4)\n",
    "print(f\"Training time: {round(elapsed4)} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388c5694",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ba5209",
   "metadata": {},
   "source": [
    "In this practice, we explored the implementation of Quantum Support Vector Machines (QSVM) using different quantum feature maps and compared their performance with classical SVMs on the breast cancer dataset. The results indicate that the choice of quantum feature map significantly impacts the model's performance. The Z Feature Map outperformed both the classical SVMs and other quantum feature maps, achieving the highest recall for the positive class labeled with 0. This suggests that certain quantum feature maps may be more effective in capturing the underlying patterns in the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
